# General Orthogonal Polynomials

A family of orthogonal polynomials is a special case of a _graded polynomial basis_:

**Definition (graded polynomial basis)**
A set of polynomials $\{p_0(x), p_1(x), â€¦ \}$ is _graded_ if $p_n$ is
precisely degree $n$: i.e.,
$$
p_n(x) = k_n x^n + k_n^{(1)} x^{n-1} + â‹¯ + k_n^{(n-1)} x + k_n^{(n)}
$$
for $k_n â‰  0$.
âˆŽ

Note that if $p_n$ are graded then $\{p_0(x), â€¦, p_n(x) \}$
are a basis of all polynomials of degree $n$.


**Definition (Orthogonal Polynomials)**
Given an (integrable) _weight_ $w(x) > 0$ for $x âˆˆ (a,b)$,
which defines a continuous inner product
$$
âŸ¨f,gâŸ© = âˆ«_a^b  f(x) g(x) w(x) {\rm d} x
$$
a graded polynomial basis $\{p_0(x), p_1(x), â€¦ \}$
are _orthogonal polynomials (OPs)_ if
$$
âŸ¨p_n,p_mâŸ© = 0
$$
whenever $n â‰  m$. We assume throughout that integrals of polynomials are finite:
$$
âˆ«_a^b  x^k w(x) {\rm d} x < âˆž.
$$
âˆŽ


Note in the above
$$
h_n := âŸ¨p_n,p_nâŸ© = \|p_n\|^2 = âˆ«_a^b  p_n(x)^2 w(x) {\rm d} x > 0.
$$

Multiplying any orthogonal polynomial by a nonzero constant necessarily is also an orthogonal
polynomial. We have two standard normalisations:


**Definition (Orthonormal Polynomials)**
A set of orthogonal polynomials $\{q_0(x), q_1(x), â€¦ \}$
are _orthonormal_ if $\|q_n\| = 1$.
âˆŽ

**Definition (Monic Orthogonal Polynomials)**
A set of orthogonal polynomials $\{Ï€_0(x), Ï€_1(x), â€¦ \}$
are _monic_ if $k_n = 1$.
âˆŽ


**Proposition (existence)** Given a weight $w(x)$, monic orthogonal polynomials
exist.

**Proof**
Existence follows immediately from the Gramâ€“Schmidt procedure. That is,
define $Ï€_0(x) := 1$ and
$$
Ï€_n(x) := x^n - âˆ‘_{k=0}^{n-1} {âŸ¨x^n,Ï€_kâŸ© \over \|Ï€_k\|^2} Ï€_k(x).
$$
Assume $Ï€_m$ are monic OPs for all $m < n$. Then we have
$$
âŸ¨Ï€_m, Ï€_nâŸ© = âŸ¨Ï€_m, x^n âŸ© - âˆ‘_{k=0}^{n-1} {âŸ¨x^n,Ï€_kâŸ© \over \|Ï€_k\|^2} \underbrace{âŸ¨Ï€_m, Ï€_kâŸ©}_{= 0 \hbox{ if $m â‰  k$}}  = âŸ¨Ï€_m, x^n âŸ© - âŸ¨x^n,Ï€_mâŸ© = 0.
$$

âˆŽ


We are primarly concerned with the usage of orthogonal polynomials in
approximating functions. First we observe the following:

**Proposition (expansion)**
If $r(x)$ is a degree $n$ polynomial and $\{p_n\}$ are orthogonal then
$$
r(x) = âˆ‘_{k=0}^n {âŸ¨p_k,râŸ© \over \|p_k\|^2} p_k(x).
$$
Note for $\{q_n\}$ orthonormal we have
$$
r(x) = âˆ‘_{k=0}^n âŸ¨q_k,râŸ© q_k(x).
$$

**Proof**
Because $\{p_0,â€¦,p_n \}$ are a basis of polynomials we can
write
$$
r(x) = âˆ‘_{k=0}^n r_k p_k(x)
$$
for constants $r_k âˆˆ â„$.
By linearity we have
$$
âŸ¨p_m,râŸ© = âˆ‘_{k=0}^n r_k âŸ¨p_m,p_kâŸ©= r_m âŸ¨p_m,p_mâŸ©
$$
which implies that $r_m = âŸ¨p_m,râŸ©/âŸ¨p_m,p_mâŸ©$.
âˆŽ

**Corollary (zero inner product)**
If a degree $n$ polynomial $r$ satisfies
$$
0 = âŸ¨p_0,râŸ© = â€¦ = âŸ¨p_n,râŸ©
$$
then $r = 0$.

**Proof**
If all the inner products are zero the coefficients in the expansion are all zero and $r$ is zero.
âˆŽ

**Corollary (uniqueness)**
Monic orthogonal polynomials are unique.

**Proof**
If $p_n(x)$ and $Ï€_n(x)$ are both monic orthogonal polynomials
then $r(x) = p_n(x) - Ï€_n(x)$ is degree $n-1$ but satisfies
$$
âŸ¨r, Ï€_kâŸ© = âŸ¨p_n, Ï€_kâŸ© - âŸ¨Ï€_n, Ï€_kâŸ© = 0
$$
for $k = 0,â€¦,{n-1}$. Note $âŸ¨p_n, Ï€_kâŸ© = 0$ can be seen by
expanding
$$
Ï€_k(x) = âˆ‘_{j=0}^k c_j p_j(x).
$$
âˆŽ


OPs are uniquely defined (up to a constant) by the
property that they are orthogonal to all lower degree polynomials.

**Theorem (orthogonal to lower degree)**
Given a weight $w(x)$,
a polynomial
$$
p(x) = k_n x^n + O(x^{n-1})
$$
with $k_n â‰  0$ satisfies
$$
âŸ¨p,f_mâŸ© = 0
$$
for all  polynomials $f_m$ of degree $m < n$ if and only if
$p(x) = k_n Ï€_n(x)$ where $Ï€_n(x)$ are the monic orthogonal polynomials.
Therefore an orthogonal polynomial is uniquely
defined by the weight and leading order coefficient $k_n$.

**Proof**
We leave this proof to the problem sheets.
âˆŽ




## Three-term recurrence

The most _fundamental_ property of orthogonal polynomials is their three-term
recurrence.

**Theorem (3-term recurrence, 2nd form)**
If $\{p_n\}$ are OPs then there exist real constants
$a_n b_n, c_{n-1}$
such that
$$
\begin{align*}
x p_0(x) &= a_0 p_0(x) + b_0 p_1(x)  \\
x p_n(x) &= c_{n-1} p_{n-1}(x) + a_n p_n(x) + b_n p_{n+1}(x),
\end{align*}
$$
where $b_n â‰ 0$ and $c_{n-1} â‰ 0$.
**Proof**
The $n=0$ case is immediate since $\{p_0,p_1\}$ are a basis of degree 1 polynomials.
The $n >0$ case follows from
$$
âŸ¨x p_n, p_kâŸ© = âŸ¨ p_n, xp_kâŸ© = 0
$$
for $k < n-1$ as $x p_k$ is of degree $k+1 < n$.

Note that
$$
b_n = {âŸ¨p_{n+1}, x p_nâŸ© \over \|p_{n+1} \|^2} â‰  0
$$
since $x p_n = k_n x^{n+1} + O(x^n)$ is precisely degree
$n$. Further,
$$
c_{n-1} = {âŸ¨p_{n-1}, x p_nâŸ© \over \|p_{n-1}\|^2 } =
{âŸ¨p_n, x p_{n-1}âŸ©  \over \|p_{n-1}\|^2 } =  b_{n-1}{\|p_n\|^2  \over \|p_{n-1}\|^2 } â‰  0.
$$



âˆŽ




Clearly if $Ï€_n$ is monic then so is $x Ï€_n$ which leads to the following:

**Corollary (monic 3-term recurrence)** $\{Ï€_n\}$ are monic if and only if $b_n =  1$.
**Proof**

If $b_n = 1$ and $Ï€_n(x) = x^n + O(x^{n-1})$ then the 3-term recurrence shows us that
$$
Ï€_{n+1}(x) = x Ï€_n(x) - c_{n-1} Ï€_{n-1}(x) - a_n Ï€_n(x) = x^{n+1} + O(x^n)
$$
and $Ï€_{n+1}(x)$ is also monic. Similarly, if $Ï€_n(x)$ is monic and $b_n â‰  1$ then $Ï€_{n+1}(x)$ is not
monic, which would be a contradiction.
âˆŽ


Note this implies that we can define $Ï€_{n+1}(x)$ in terms of $Ï€_{n-1}$ and $Ï€_n$:
$$
Ï€_{n+1}(x) = x Ï€_n(x) - a_n Ï€_n(x) - c_{n-1} Ï€_{n-1}(x)
$$
where
$$
a_n = {âŸ¨x Ï€_n, Ï€_nâŸ© \over \| Ï€_n\|^2} \qquad \hbox{and} \qquad c_{n-1} = {âŸ¨x Ï€_n, Ï€_{n-1}âŸ© \over \| Ï€_{n-1}\|^2}.
$$


**Example (constructing OPs)** What are the  monic OPs $Ï€_0(x),â€¦,Ï€_3(x)$ with respect to $w(x) = 1$ on $[0,1]$?
We can construct these using Gramâ€“Schmidt, but exploiting the 3-term recurrence to reduce the computational cost.
We have $Ï€_0(x) = 1$, which we see is already normalised:
$$
\|Ï€_0\|^2 = âŸ¨Ï€_0,Ï€_0âŸ© = âˆ«_0^1 {\rm d} x = 1.
$$
We know from the 3-term recurrence that
$$
x Ï€_0(x) = a_0 Ï€_0(x) +  Ï€_1(x)
$$
where
$$
a_0 = {âŸ¨Ï€_0,x Ï€_0âŸ©  \over \|Ï€_0\|^2} = âˆ«_0^1 x {\rm d} x = 1/2.
$$
Thus
$$
\begin{align*}
Ï€_1(x) = x Ï€_0(x) - a_0 Ï€_0(x) = x-1/2 \qquad  â‡’ \\
\|Ï€_1\|^2 = âˆ«_0^1 (x^2 - x + 1/4) {\rm d} x = 1/12.    
\end{align*}
$$
From
$$
x Ï€_1(x) = c_0 Ï€_0(x) + a_1 Ï€_1(x) +  Ï€_2(x)
$$
we have
$$
\begin{align*}
c_0 &= {âŸ¨Ï€_0,x Ï€_1âŸ©  \over \|Ï€_0\|^2} = âˆ«_0^1 (x^2 - x/2) {\rm d} x = 1/12, \\
a_1 &= {âŸ¨Ï€_1,x Ï€_1âŸ©  \over \|Ï€_1\|^2} = 12 âˆ«_0^1 (x^3 - x^2 + x/4) {\rm d} x = 1/2, \\
Ï€_2(x) &= x Ï€_1(x) - c_0 - a_1 Ï€_1(x) = x^2 - x + 1/6 \qquad â‡’ \\
\|Ï€_2\|^2 &= \int_0^1 (x^4 - 2x^3 + 4x^2/3 - x/3 + 1/36) {\rm d} x = {1 \over 180}
\end{align*}
$$
Finally, from
$$
x Ï€_2(x) = c_1 Ï€_1(x) + a_2 Ï€_2(x) +  Ï€_3(x)
$$
we have
$$
\begin{align*}
c_1 &= {âŸ¨Ï€_1,x Ï€_2âŸ©  \over \|Ï€_1\|^2} = 12 âˆ«_0^1 (x^4 - 3x^3/2 +2x^2/3 -x/12)  {\rm d} x = 1/15, \\
a_2 &= {âŸ¨Ï€_2,x Ï€_2âŸ©  \over \|Ï€_2\|^2} = 180 âˆ«_0^1 (x^5 - 2x^4 +4x^3/3 - x^2/3 + x/36) {\rm d} x = 1/2, \\
Ï€_3(x) &= x Ï€_2(x) - c_1 Ï€_1(x)- a_2 Ï€_2(x) \ccr 
= x^3 - x^2 + x/6 - x/15 + 1/30 -x^2/2 + x/2 - 1/12 \\
&= x^3 - 3x^2/2 + 3x/5 -1/20
\end{align*}
$$
âˆŽ

## Jacobi matrices


The three-term recurrence can also be interpreted as a matrix:

**Corollary (multiplication matrix)**
For
$$
P(x) := [p_0(x) | p_1(x) | â‹¯]
$$
then we have
$$
x P(x) = P(x) \underbrace{\begin{bmatrix} a_0 & c_0 \\
                                                        b_0 & a_1 & c_1\\
                                                        & b_1 & a_2 & â‹± \\
                                                        && â‹± & â‹±
                                                        \end{bmatrix}}_X
$$
More generally, for any polynomial $a(x)$ we have
$$
a(x) P(x) = P(x) a(X).
$$

**Proof**
The expression follows:
$$
x P(x) = [xp_0(x) | xp_1(x) | â‹¯] =
[a_0p_0(x) + b_0 p_1(x) | c_0 p_0(x) + a_1 p_1(x) + b_1 p_2(x) | â‹¯] = P(x) X.
$$
For polynomials, note that
$$
x^k P(x) = x^{k-1} P(x) X = â‹¯ = P(x) X^k.
$$
Thus if $a(x) = âˆ‘_{k=0}^n a_k x^k$ we have by linearity
$$
a(x) P(x) = âˆ‘_{k=0}^n a_k x^k P(x) = P(x) âˆ‘_{k=0}^n a_k X^k = P(x) a(X).
$$
âˆŽ

**Remark** If you are worried about multiplication of infinite matrices/vectors
note it is well-defined by the standard definition because it is banded.
It can also be defined in terms of functional analysis where one considers these
as linear operators (functions of functions) between vector spaces.


For the special cases of orthonormal polynomials we have extra structure,
in which case we refer to the matrix as a _Jacobi matrix_:

**Corollary (Jacobi matrix)**
The multiplication matrix of a family of orthogonal polynomials $p_n(x)$ is symmetric,
$$
X = X^âŠ¤ = \begin{bmatrix} a_0 & b_0 \\
                                                        b_0 & a_1 & b_1\\
                                                        & b_1 & a_2 & â‹± \\
                                                        && â‹± & â‹±
                                                        \end{bmatrix},
$$
if and only if $p_n(x)$ is up-to-sign a fixed constant scaling of orthonormal:
for $q_n(x) := Ï€_n(x)/\|Ï€_n\|$ we have for a fixed $Î± âˆˆ â„$ and $s_n âˆˆ \{-1,1\}$
$$
p_n(x) = Î± s_n q_n(x).
$$

**Proof**
First, assume $p_n(x)$ has the specified form. Noting that $\|q_n\|^2 = 1$ and thence $\|p_n\|^2 = Î±^2$,
if $p_n(x) = Î± s_n q_n(x)$ we have
$$
b_n = {âŸ¨xp_n, p_{n+1}âŸ© \over \|p_{n+1}\|^2} = s_n s_{n+1} âŸ¨x q_n, q_{n+1}âŸ© =
s_n s_{n+1} âŸ¨q_n, x q_{n+1}âŸ© = {âŸ¨p_n, xp_{n+1}âŸ© \over \|p_n\|^2} = c_{n}
$$
and therefore $X$ is symmetric.

Conversely, suppose $X = X^âŠ¤$, i.e., $b_n = c_{n}$ and write the corresponding
orthogonal polynomials as $p_n(x) = Î±_n q_n(x)$. We have
$$
\meeq{
b_n = {âŸ¨xp_n, p_{n+1}âŸ© \over \|p_{n+1}\|^2} =
{Î±_n \over Î±_{n+1}} âŸ¨xq_n, q_{n+1}âŸ© =
{Î±_n \over Î±_{n+1}} âŸ¨q_n, x q_{n+1}âŸ© = {Î±_n^2 \over Î±_{n+1}^2} {âŸ¨p_n, xp_{n+1}âŸ© \over \|p_n\|^2}
\ccr
= {Î±_n^2 \over Î±_{n+1}^2} c_{n} = {Î±_n^2 \over Î±_{n+1}^2} b_n.
}
$$
Hence $Î±_n^2 = Î±_{n+1}^2$ which implies that $Î±_{n+1} = Â± Î±_n$. By induction the result follows,
where $Î± := Î±_0$.
âˆŽ


**Remark** Every compactly supported integrable weight generates a family of
orthonormal polynomials, which in turn generates a Jacobi matrix.
There is a â€œSpectral Theorem for Jacobi matrices" that says one can go the
other way: every tridiagonal symmetric matrix with bounded entries is a Jacobi
matrix for some integrable weight with compact support. This is an example of what
[Barry Simon](https://en.wikipedia.org/wiki/Barry_Simon) calls a â€œGem of spectral theory".


**Example (uniform weight orthonormal polynomials)** Consider computing orthonormal polynomials 
with respect to $w(x) = 1$ on $[0,1]$. Above we constructed the monic OPs $Ï€_0(x),â€¦,Ï€_3(x)$ so we
can deduce the orthonormal polynomials by dividing by their norm, but there is another way: writing 
$q_n(x) = k_n Ï€_n(x)$, find the
normalisation $k_n$ that turns the 3-term recurrence into a symmetric matrix. 
We can write the 3-term recurrence coefficients for monic OPs as a multiplication matrix:
$$
x [Ï€_0(x)| Ï€_1(x)| â‹¯] = [Ï€_0(x)| Ï€_1(x)| â‹¯] \underbrace{\begin{bmatrix} 1/2 & 1/12 \\
                                                            1 & 1/2 & 1/15 \\
                                                            & 1 & 1/2 & â‹± \\
                                                            & & 1 & â‹± & â‹± \\
                                                            &&& â‹± \end{bmatrix}}_X
$$
The previous theorem says that if we rescale the polynomials so that the resulting Jacobi matrix is
symmetric than they are by necessity the orthonormal polynomials. In particular, consider writing:
$$
[q_0(x) | q_1(x) | â‹¯] = [Ï€_0(x)| Ï€_1(x)| â‹¯] \underbrace{\begin{bmatrix}  k_0 \\ & k_1 \\ && k_2 \\ &&& â‹± \end{bmatrix}}_K
$$
where we want to find the normalisation constants. Since $\|Ï€_0\| = 1$ we know $k_0 = 1$. We have
$$
x [q_0(x) | q_1(x) | â‹¯] = [Ï€_0(x)| Ï€_1(x)| â‹¯] X K = [q_0(x) | q_1(x) | â‹¯] \underbrace{K^{-1} X K}_{J}
$$
where
$$
J = \begin{bmatrix} a_0 & c_0 k_1 \\
                         k_1^{-1} & a_1 & c_1 k_2/k_1 \\
                         & k_1/k_2 & a_2 & c_2 k_3/k_2 \\
                         &&â‹± & â‹± & â‹± \end{bmatrix}.
$$
Thus for this to be symmetric we need
$$
c_0 k_1 = k_1^{-1}, c_1 k_2/k_1 = k_2^{-1}, c_2 k_3/k_2 = k_3^{-1}, â€¦
$$
Note that
$$
c_2 = {âŸ¨Ï€_2,x Ï€_3âŸ©  \over \|Ï€_2\|^2} = 180 âˆ«_0^1 (x^6 -5x^5/2 + 34x^4/15 - 9x^3/10 + 3x^2/20 - x/120){\rm d} x = 9/140.
$$
Thus we have (noting that the $k_n$ are all positive which simplifies the square-roots):
$$
\meeq{
k_1 = 1/\sqrt{c_0} = 2\sqrt{3}, \ccr
k_2 = k_1/\sqrt{c_1} = 6\sqrt{5}, \ccr
k_3 =  k_2/\sqrt{c_2} = 20 \sqrt{7}.
}
$$
Thus we have
$$
\begin{align*}
q_0(x) &= Ï€_0(x) = 1, \\
q_1(x) &= 2\sqrt{3} Ï€_1(x)= \sqrt{3} (2  x - 1), \\
q_2(x) &= 6\sqrt{5} Ï€_2(x) = \sqrt{5} (6x^2 - 6x + 1), \\
q_3(x) &= 20 \sqrt{7} Ï€_3(x) = \sqrt{7} (20x^3-30x^2 + 12x - 1),
\end{align*}
$$
which have the Jacobi matrix
$$
\begin{align*}
J =
     \begin{bmatrix} 1/2 & 1/(2\sqrt{3}) \\
                    1/(2\sqrt{3}) & 1/2 &  1/\sqrt{15} \\
                    & 1/\sqrt{15} & 1/2 & 3/(2 \sqrt{35}) \\
                    && 3/(2 \sqrt{35}) &  1/2 & â‹± \\
                    &&& & â‹± & â‹± \end{bmatrix}.
\end{align*}
$$
âˆŽ


**Example (expansion via Jacobi matrix)** What are the expansion coefficients of $x^3 - x + 1$ in $\{q_n\}$? We could
deduce this by computing the inner products though its actually simpler to use the multiplication matrix. In particular if we write
$$
Q(x) := [q_0(x) | q_1(x) | q_2(x) | â‹¯]
$$
Then we have (note: $q_0(x) â‰¡ 1$ only because the weight integrates to 1) $1 = Q(x) ðž_1$.
This tells us that:
$$
x = x Q(x) ðž_1 = Q(x) X ðž_1 = Q(x) \Vectt[1/2, 1/(2\sqrt{3}), 0, â‹®].
$$
Continuing we have
$$
\meeq{
x^2 = Q(x)  X \Vectt[1/2, 1/(2\sqrt{3}), 0, â‹®] = Q(x) \Vectt[1/3, 1/(2 \sqrt{3}),  1/(6\sqrt{5}),0,â‹® ] \ccr
x^3 = Q(x) X  \Vectt[1/3, 1/(2 \sqrt{3}),  1/(6\sqrt{5}),0,â‹® ] =
 Q(x) \Vectt[1/4,{3 \sqrt{3} \over 20}, {1 \over 4 \sqrt{5}}, {1 \over 20 \sqrt{7}}, 0, â‹®]
}
$$
Thus by linearity we find that
$$
\meeq{
x^3 - x + 1 = Q(x) \Vectt[3/4, -1/(20\sqrt{3}), {1 \over 4 \sqrt{5}}, {1 \over 20 \sqrt{7}}, 0, â‹®] \ccr
= {3 \over 4} q_0(x) - {1 \over 20\sqrt{3}} q_1(x) + {1 \over 4 \sqrt{5}} q_2(x) + {1 \over 20 \sqrt{7}} q_3(x).
}
$$
âˆŽ