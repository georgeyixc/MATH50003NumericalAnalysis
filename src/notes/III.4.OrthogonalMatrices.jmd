# Orthogonal and Unitary Matrices

To solve least squares problems, we will  factorise a matrix $A$ as $A = QR$
where $R$ is a _right-triangular matrix_ and $Q$ is either an _orthogonal_ or _unitary_ matrix.

**Definition (orthogonal/unitary matrix)** A square real matrix is _orthogonal_ if its inverse is its transpose:
$$
O(n) = \{Q âˆˆ â„^{n Ã— n} : Q^âŠ¤Q = I \}
$$
A square complex matrix is _unitary_ if its inverse is its adjoint:
$$
U(n) = \{Q âˆˆ â„‚^{n Ã— n} : Q^â‹†Q = I \}.
$$
Here the adjoint is the same as the conjugate-transpose: $Q^â‹† := \bar Q^âŠ¤$. 
âˆ


Note that $O(n) âŠ‚ U(n)$ as for real matrices $Q^â‹† = Q^âŠ¤$. Because in either case $Q^{-1} = Q^â‹†$ we also have
$Q Q^â‹† = I$ (which for real matrices is $Q Q^âŠ¤ = I$). These matrices are particularly important for
numerical linear algebra for a number of reasons (we'll explore these properties in the problem sheets):

1. They are norm-preserving: for any vector $ğ± âˆˆ â„‚^n$ and $Q âˆˆ U(n)$    we have $\|Q ğ± \| = \| ğ±\|$ where $\| ğ± \|^2 := âˆ‘_{k=1}^n x_k^2$ (i.e. the 2-norm).
2. All eigenvalues have absolute value equal to $1$.
3. For $Q âˆˆ O(n)$,  $\det Q = Â±1$.
2. They are trivially invertible (just take the adjoint).
3. They are generally â€œstable": errors due to rounding when multiplying a vector by $Q$ are controlled.
4. They are _normal matrices_: they commute with their adjoint ($Q Q^â‹† = Q Q^â‹†$). 
5. Both $O(n)$ and $U(n)$ are groups, in particular, they are closed under multiplication.

On a computer there are multiple ways of representing orthogonal/unitary matrices,
and it is almost never to store a dense matrix, that is, we do not want to store all the entries.
In the appendices we have seen permutation matrices, which
are a special type of orthogonal matrices where we can store only the order the entries are permuted as a vector. 

More generally, we will use the group structure: represent general orthogonal/unitary matrices as products of simpler
elements of the group. In partular we will use two building blocks:


1. _Rotations_: Rotations are equivalent to special orthogonal matrices $SO(2)$  and correspond to rotations in 2D.
2. _Reflections_:  Reflections are elements of $U(n)$ that are defined in terms of a single unit vector $ğ¯ âˆˆ â„‚^n$ which is reflected.

We remark a related concept to orthogonal/unitary matrices are rectangular matrices with orthonormal columns, e.g.
$$
U = [ğ®_1 | â‹¯ | ğ®_n] âˆˆ â„‚^{m Ã— n}
$$
where $m â‰¥ n$ such that $U^â‹† U =  I_n$ (the $n Ã— n$ identity matrix). In this case we must have $UU^â‹† â‰  I_m$ as the rank of $U$ is $n < m$. 


## Rotations

We begin with a general definition:

**Definition (Special Orthogonal and Rotations)** _Special Orthogonal Matrices_ are
$$
SO(n) := \{Q âˆˆ O(n) | \det Q = 1 \}
$$
And (simple) _rotations_ are $SO(2)$.
âˆ

In what follows we use the following for writing the angle of a vector:

**Definition (two-arg arctan)** The two-argument arctan function gives the angle `Î¸` through the point
$[a,b]^âŠ¤$, i.e., 
$$
\sqrt{a^2 + b^2} \begin{bmatrix} \cos Î¸ \\ \sin Î¸ \end{bmatrix} =  \begin{bmatrix} a \\ b \end{bmatrix}.
$$
It can be defined in terms of the standard arctan as follows:
$$
{\rm atan}(b,a) := \begin{cases} {\rm atan}{b \over a} & a > 0 \\
                            {\rm atan}{b \over a} + Ï€ & a < 0\hbox{ and }b >0 \\
                            {\rm atan}{b \over a} - Ï€ & a < 0\hbox{ and }b < 0 \\
                            Ï€/2 & a = 0\hbox{ and }b >0 \\
                            -Ï€/2 & a = 0\hbox{ and }b < 0 
                            \end{cases}
$$
âˆ


We show $SO(2)$ are exactly equivalent to standard rotations:


**Proposition (simple rotation)**
A 2Ã—2 _rotation matrix_ through angle $Î¸$ is
$$
Q_Î¸ := \begin{bmatrix} \cos Î¸ & -\sin Î¸ \cr \sin Î¸ & \cos Î¸ \end{bmatrix}.
$$
We have $Q âˆˆ SO(2)$ if and only if $Q = Q_Î¸$ for some $Î¸ âˆˆ â„$.

**Proof**

We will write $c = \cos Î¸$ and $s = \sin Î¸$. Then we have
$$
Q_Î¸^âŠ¤Q_Î¸ = \begin{pmatrix} c & s \\ -s & c \end{pmatrix} \begin{pmatrix} c & -s \\ s & c \end{pmatrix} = 
\begin{pmatrix} c^2 + s^2 & 0 \\ 0 & c^2 + s^2 \end{pmatrix} = I
$$
and $\det Q_Î¸ = c^2 + s^2 = 1$ hence $Q_Î¸ âˆˆ SO(2)$. 

Now suppose $Q = [ğª_1, ğª_2] âˆˆ SO(2)$ where we know its columns have norm 1, i.e. $\|ğª_k\| = 1$, and are orthogonal.
Write $ğª_1 = [c,s]$ where we know $c = \cos Î¸$ and $s = \sin Î¸$ for $Î¸ = {\rm atan}(s, c)$. 
Since $ğª_1\cdot ğª_2 = 0$ we can deduce $ğª_2 = Â± [-s,c]$. The sign is positive as $\det Q = Â±(c^2 + s^2) = Â±1$.

âˆ




We can rotate an arbitrary vector in $â„^2$ to the unit axis using rotations, which are useful in
linear algebra decompositions. Interestingly it only requires
basic algebraic functions (no trigonometric functions):



**Proposition (rotation of a vector)** 
The matrix
$$
Q = {1 \over \sqrt{a^2 + b^2}}
\begin{bmatrix}
 a & b \cr -b & a
\end{bmatrix}
$$
is a rotation matrix ($Q âˆˆ SO(2)$) satisfying
$$
Q \begin{bmatrix} a \\ b \end{bmatrix} = \sqrt{a^2 + b^2} \begin{bmatrix} 1 \\ 0 \end{bmatrix}
$$

**Proof** 

The last equation is trivial so the only question is that it is a rotation matrix. This follows immediately:
$$
Q^âŠ¤ Q = {1 \over a^2 + b^2}  \begin{bmatrix}
 a^2 + b^2 & 0 \cr 0 & a^2 + b^2
\end{bmatrix} = I
$$
and $\det Q = 1$.

âˆ

**Example (rotating a vector)** Consider the vector
$$
ğ± = \Vectt[-1,-\sqrt{3}].
$$
We can use the proposition above to deduce the rotation matrix that rotates this
vector to the positive real axis is:
$$
{1 \over \sqrt{1+3}} \begin{bmatrix} -1 & -\sqrt{3} \\ \sqrt{3} & -1 \end{bmatrix} = 
{1 \over 2} \begin{bmatrix} -1 & -\sqrt{3} \\ \sqrt{3} & -1 \end{bmatrix}.
$$
Alternatively, we could determine the matrix by computing the angle of the vector via:
$$
Î¸ =  {\rm atan}(-\sqrt{3}, -1) = {\rm atan}(\sqrt{3}) - Ï€ = -{2Ï€ \over 3}.
$$
We thus compute:
$$
Q_{-Î¸} = \begin{bmatrix}
\cos(2Ï€/3) & -\sin(2Ï€/3) \\
\sin(2Ï€/3) & \cos(2Ï€/3)
\end{bmatrix} = {1 \over 2} \begin{bmatrix} -1 & -\sqrt{3} \\ \sqrt{3} & -1 \end{bmatrix}.
$$
âˆ

More generally, we can consider rotations that operate on two entries of a vector at a time.
This will be explored in the problem sheet/lab.


## Reflections

In addition to rotations, another type of orthogonal/unitary matrix are reflections. These are
specified by a single vector which is reflected, with everything orthogonal to the vector left fixed. 

**Definition (reflection matrix)** 
Given a unit vector $ğ¯ âˆˆ â„‚^n$ (satisfying $\|ğ¯\|=1$), define the corresponding _reflection matrix_ as:
$$
Q_{ğ¯} := I - 2 ğ¯ ğ¯^â‹†
$$
âˆ


These are indeed reflections in the direction of $ğ¯$. We can show this as follows:

**Proposition (Householder properties)** $Q_{ğ¯}$ satisfies:
1. Symmetry: $Q_{ğ¯} = Q_{ğ¯}^â‹†$
2. Orthogonality: $Q_{ğ¯} âˆˆ U(n)$
3. The vector $ğ¯$ is an eigenvector of $Q_{ğ¯}$ with eigenvalue $-1$
4. For the dimension $n-1$ space $W := \{ğ° : ğ°^â‹† ğ¯ = 0 \}$, all vectors $ğ° âˆˆ W$ satisfy $Q_{ğ¯}ğ° = ğ°$.
5. Not a rotation: $\det Q_{ğ¯} = -1$


**Proof**

Property 1 follows immediately. Property 2 follows from
$$
Q_{ğ¯}^â‹† Q_{ğ¯} = Q_{ğ¯}^2 = I - 4 ğ¯ ğ¯^â‹† + 4 ğ¯ ğ¯^â‹† ğ¯ ğ¯^â‹† = I.
$$
Property 3 follows since
$$
Q_{ğ¯} ğ¯ = ğ¯ - 2ğ¯ (ğ¯^â‹†ğ¯) = -ğ¯.
$$
Property 4 follows from:
$$
Q_{ğ¯} ğ° = ğ° - 2 ğ¯ (ğ°^â‹† ğ¯) =  ğ°
$$
Property 5 then follows: Property 4 tells us that
$1$ is an eigenvalue with multiplicity $n-1$. Since $-1$ is an eigenvalue with multiplicity 1,
 the determinant, which is product of the eigenvalues, is $-1$.

âˆ



**Example (reflection through 2-vector)** Consider reflection through $ğ± = [1,2]^âŠ¤$. 
We first need to normalise $ğ±$:
$$
ğ¯ = {ğ± \over \|ğ±\|} = \begin{bmatrix} {1 \over \sqrt{5}} \\ {2 \over \sqrt{5}} \end{bmatrix}
$$
The reflection matrix is:
$$
Q_{ğ¯} = I - 2 ğ¯ ğ¯^âŠ¤ = \begin{bmatrix}1 \\ & 1 \end{bmatrix} - {2 \over 5} \begin{bmatrix} 1 & 2 \\ 2 & 4 \end{bmatrix}
 =  {1 \over 5} \begin{bmatrix} 3 & -4 \\ -4 & -3 \end{bmatrix}
$$
Indeed it is symmetric, and orthogonal. It sends $ğ±$ to $-ğ±$:
$$
Q_{ğ¯} ğ± = {1 \over 5} \begin{bmatrix}3 - 8 \\ -4 - 6 \end{bmatrix} = -ğ±
$$
Any vector orthogonal to $ğ±$, like $ğ² = [-2,1]^âŠ¤$, is left fixed:
$$
Q_{ğ¯} ğ² = {1 \over 5} \begin{bmatrix}-6 -4 \\ 8 - 3 \end{bmatrix} = ğ²
$$
âˆ


Note that _building_ the matrix $Q_{ğ¯}$ will be expensive ($O(n^2)$ operations), but we can _apply_
$Q_{ğ¯}$ to a vector in $O(n)$ operations using the expression:
$$
Q_{ğ¯} ğ± = ğ± - 2 ğ¯ (ğ¯^â‹† ğ±) = ğ± - 2 ğ¯ (ğ¯ â‹… ğ±).
$$

### Householder reflections

Just as rotations can be used to rotate vectors to be aligned with coordinate axis, so can reflections,
but in this case it works for vectors in $â„‚^n$, not just $â„^2$. We begin with the real case:

**Definition (Householder reflection, real case)** For a given vector
$ğ± âˆˆ â„^n$, define the Householder reflection
$$
Q_{ğ±}^{Â±,\rm H} := Q_{ğ°}
$$
for $ğ² = âˆ“ \|ğ±\| ğ_1 + ğ±$ and $ğ° = {ğ² \over \|ğ²\|}$.
The default choice in sign is:
$$
Q_{ğ±}^{\rm H} := Q_{ğ±}^{-\hbox{sign}(x_1),\rm H}.
$$
âˆ

**Lemma (Householder reflection maps to axis)** For $ğ± âˆˆ â„^n$,
$$
Q_{ğ±}^{Â±,\rm H} ğ± = Â±\|ğ±\| ğ_1
$$

**Proof**
Note that
$$
\begin{align*}
\| ğ² \|^2 &= 2\|ğ±\|^2 âˆ“ 2 \|ğ±\| x_1, \\
ğ²^âŠ¤ ğ± &= \|ğ±\|^2 âˆ“  \|ğ±\| x_1
\end{align*}
$$
where $x_1 = ğ_1^âŠ¤ ğ±$. Therefore:
$$
Q_{ğ±}^{Â±,\rm H} ğ±  =  (I - 2 ğ° ğ°^âŠ¤) ğ± = ğ± - 2 {ğ²  \|ğ±\|  \over \|ğ²\|^2} (\|ğ±\|âˆ“x_1) = ğ± - ğ² =  Â±\|ğ±\| ğ_1.
$$

âˆ

**Remark** Why do we choose the the opposite sign of $x_1$ for the default reflection? For stability, but
we won't discuss this in more detail.

We can extend this definition for complexes:

**Definition (Householder reflection, complex case)** For a given vector
$ğ± âˆˆ â„‚^n$, define the Householder reflection as
$$
Q_{ğ±}^{\rm H} := Q_{ğ°}
$$
for $ğ² = {\rm csign}(x_1) \|ğ±\| ğ_1 + ğ±$ and $ğ° = {ğ² \over \|ğ²\|}$, for ${\rm csign}(z) = {\rm e}^{{\rm i} \arg z}$. 
âˆ


**Lemma (Householder reflection maps to axis, complex case)** For $ğ± âˆˆ â„‚^n$,
$$
Q_{ğ±}^{\rm H} ğ± = -{\rm csign}(x_1) \|ğ±\| ğ_1
$$

**Proof**
Denote $Î± := {\rm csign}(x_1)$. 
Note that $\baralpha x_1 = {\rm e}^{-{\rm i} \arg x_1} x_1 = |x_1|$.  Now we have
$$
\begin{align*}
\| ğ² \|^2 &= (Î± \|ğ±\| ğ_1 + ğ±)^â‹†(Î± \|ğ±\| ğ_1 + ğ±) = |Î±|\| ğ± \|^2 + \| ğ± \|  Î± \bar x_1 + \baralpha x_1 \| ğ± \| + \| ğ± \|^2 \\
&= 2\| ğ± \|^2 + 2|x_1| \| ğ± \| \\
ğ²^â‹† ğ± &= \baralpha x_1 \| ğ± \| + \|ğ± \|^2 = \|ğ± \|^2 + |x_1| \| ğ± \|
\end{align*}
$$
Therefore:
$$
Q_{ğ±}^{\rm H} ğ±  =  (I - 2 ğ° ğ°^â‹†) ğ± = ğ± - 2 {ğ²    \over \|ğ²\|^2} (\|ğ± \|^2 + |x_1| \|ğ± \|) = ğ± - ğ² =  -Î± \|ğ±\| ğ_1.
$$

âˆ