{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MATH50003 (2024â€“25)\n",
    "# Lab 7: IV.1 Polynomial Interpolation and Regression and IV.2 Differential Equations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We  explore polynomial interpolation and regression, and see that when\n",
    "interpolating at an evenly spaced grid one can encounter issues with convergence.\n",
    "This is overcome via regression, but we are left with the question of how to\n",
    "solve the underlying least squares problems."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We also explore the reduction of differential equations to\n",
    "banded linear systems via divided differences. When we get lower bidiagonal systems these can be solved\n",
    "using forward substitution, whereas we will discuss the tridiagonal case later."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Learning Outcomes**\n",
    "\n",
    "Mathematical knowledge:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Vandermonde matrices and least squares.\n",
    "2. Constructing interpolatory quadrature rules.\n",
    "2. Issues with interpolation at evenly spaced points with functions with small radii of convergence.\n",
    "3. Reduction of differential equations to bidiagonal or tridiagonal linear systems.\n",
    "4. Two-point boundary value problems and their convergence rates."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Coding knowledge:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. The error function `erfi` as provided by SpecialFunctions.jl."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We first load  packages we need including a couple new ones:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# LinearAlgebra contains routines for doing linear algebra\n",
    "using LinearAlgebra, Plots, Test"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Remark** One should normally not need to implement methods for solving differential equations\n",
    "oneself as there are packages available, including the high-performance\n",
    " Julia package  [DifferentialEquations.jl](https://github.com/SciML/DifferentialEquations.jl). Moreover Forward and Backward\n",
    "Euler are only the first baby steps to a wide range of time-steppers, with Rungeâ€“Kutta being\n",
    "one of the most successful.\n",
    "For example, in practice we can solve\n",
    "a simple differential equation like a pendulum $u'' = -\\sin u$ can be solved\n",
    "as follows (writing at a system $u' = v, v' = -\\sin u$):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using DifferentialEquations, LinearAlgebra, Plots\n",
    "\n",
    "u = solve(ODEProblem((u,_,x) -> [u[2], -sin(u[1])], [1,0], (0,10)))\n",
    "plot(u)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, even in these automated packages one has a choice of different methods with\n",
    "different behaviour, so it is important to understand on a mathematical level what is happening under the hood."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IV.1 Polynomial Interpolation and Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now explore the practical usage of polynomial interpolation and regression.\n",
    "In particular we will see that polynomial interpolation may fail as the number\n",
    "of points becomes large."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IV.1.1 Polynomial Interpolation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A quick-and-dirty way to to do interpolation is to invert the Vandermonde matrix.\n",
    "That is, for\n",
    "$$\n",
    "p(x) = âˆ‘_{k = 0}^{n-1} c_k x^k\n",
    "$$\n",
    "and $x_1, â€¦, x_n âˆˆ â„$, we choose $c_k$ so that $p(x_j) = f(x_j)$ for\n",
    "$j = 1, â€¦, n$. We do so by creating the square Vandermonde matrix\n",
    "$$\n",
    "V := \\begin{bmatrix} 1 & x_1 & â‹¯ & x_1^{n-1} \\\\\n",
    "                    â‹® & â‹® & â‹± & â‹® \\\\\n",
    "                    1 & x_n & â‹¯ & x_n^{n-1}\n",
    "                    \\end{bmatrix}.\n",
    "$$\n",
    "If the function samples are\n",
    "$$\n",
    " ðŸ = \\begin{bmatrix} f(x_1) \\\\ â‹® \\\\ f(x_n) \\end{bmatrix}\n",
    "$$\n",
    "then the coefficients of the interpolatory polynomial\n",
    "$$\n",
    "      ðœ = \\begin{bmatrix}\n",
    "          c_0 \\\\ â‹® \\\\ c_{n-1} \\end{bmatrix}\n",
    "$$\n",
    "must satisfy $V ðœ = ðŸ$.  Thus inverting the Vandermonde matrix tells us the coefficients."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we see an example of this using `n` evenly spaced points:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "f = x -> cos(10x)\n",
    "n = 5\n",
    "ð± = range(0, 1; length=n) # evenly spaced points (BAD for interpolation)\n",
    "V =  [ð±[j]^k for j = 1:n, k = 0:n-1] # Vandermonde matrix, also can be written as x .^ (0:n)'\n",
    "ðŸ = f.(ð±) # evaluate f at x[k], equivalent to [f(x[k]) for k = 1:n]\n",
    "ðœ = V \\ ðŸ # invert the Vandermonde matrix and determine the coefficients\n",
    "p = x -> dot(ðœ, x .^ (0:n-1)) # take a dot product with monomials x .^ 0:n-1 == [x^j for j=0:n-1]\n",
    "@test p.(ð±) â‰ˆ V * ðœ # evaluating the polynomial on x is the same as applying V\n",
    "\n",
    "\n",
    "ð  = range(0,1; length=1000) # plotting grid, sample a lot more than interpolation points\n",
    "\n",
    "# To evaluate a polynomial on the plotting grid its faster to create the rectangular Vandermonde matrix associated with that grid:\n",
    "V_g = [ð [j]^k for j = 1:length(ð ), k = 0:n-1]\n",
    "\n",
    "plot(ð , f.(ð ); label=\"function\")\n",
    "plot!(ð , V_g*ðœ; label=\"interpolation\")\n",
    "scatter!(ð±, f.(ð±); label=\"samples\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Whether an interpolation is actually close to a function is a subtle question,\n",
    "involving properties of the function, distribution of the sample points $x_1,â€¦,x_n$,\n",
    "and round-off error.\n",
    "A classic example is:\n",
    "$$\n",
    "  f_M(x) = {1 \\over M x^2 + 1}\n",
    "$$\n",
    "where the choice of $M$ can dictate whether interpolation at evenly spaced points converges."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 1** Interpolate $1/(4x^2+1)$ and $1/(25x^2 + 1)$ at an evenly spaced grid of $n$\n",
    "points, plotting the solution at a grid of $1000$ points. For $n = 50$ does your interpolation match\n",
    "the true function?  Does increasing $n$ to 400 improve the accuracy? How about using `BigFloat`?\n",
    "Hint: make sure to make your `range` be `BigFloat` valued, e.g., `range(big(-1), big(1); length=n)`."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: interpolate 1/(10x^2 + 1) and 1/(25x^2 + 1) at $n$ evenly spaced points, plotting both solutions evaluated at\n",
    "# the plotting grid with 1000 points, for $n = 50$ and $400$.\n",
    "\n",
    "# SOLUTION\n",
    "\n",
    "n = 50\n",
    "ð± = range(-1, 1; length=n)\n",
    "ð  = range(-1, 1; length=1000) # plotting grid\n",
    "\n",
    "V = ð± .^ (0:n-1)'\n",
    "V_g = ð  .^ (0:n-1)'\n",
    "\n",
    "f_4 = x -> 1/(4x^2 + 1)\n",
    "ðœ_4 = V \\ f_4.(ð±)\n",
    "f_25 = x -> 1/(25x^2 + 1)\n",
    "ðœ_25 = V \\ f_25.(ð±)\n",
    "\n",
    "plot(ð , V_g*ðœ_4; ylims=(-1,1))\n",
    "plot!(ð , V_g*ðœ_25)\n",
    "# We see large errors near Â±1 for both examples.\n",
    "\n",
    "\n",
    "n = 400\n",
    "ð± = range(-1, 1; length=n)\n",
    "\n",
    "V = ð± .^ (0:n-1)'\n",
    "V_g = ð  .^ (0:n-1)'\n",
    "f_4 = x -> 1/(4x^2 + 1)\n",
    "ðœ_4 = V \\ f_4.(ð±)\n",
    "f_25 = x -> 1/(25x^2 + 1)\n",
    "ðœ_25 = V \\ f_25.(ð±)\n",
    "\n",
    "plot(ð , V_g*ðœ_4; ylims=(-1,1))\n",
    "plot!(ð , V_g*ðœ_25)\n",
    "#  M = 4 appears to converge whilst M = 25 breaks down.\n",
    "\n",
    "# Now do big float\n",
    "n = 400\n",
    "ð± = range(big(-1), 1; length=n)\n",
    "ð  = range(big(-1), 1; length=1000) # plotting grid\n",
    "\n",
    "V = ð± .^ (0:n-1)'\n",
    "V_g = ð  .^ (0:n-1)'\n",
    "\n",
    "f_4 = x -> 1/(4x^2 + 1)\n",
    "ðœ_4 = V \\ f_4.(ð±)\n",
    "f_25 = x -> 1/(25x^2 + 1)\n",
    "ðœ_25 = V \\ f_25.(ð±)\n",
    "\n",
    "plot(ð , V_g*ðœ_4; ylims=(-1,1))\n",
    "plot!(ð , V_g*ðœ_25)\n",
    "# With M = 4 it looks like it now is converging. This suggests the issue before was numerical error.\n",
    "# For M = 25 the solution is even less accurate, which suggests the issue is a lack of mathematical\n",
    "# convergence.\n",
    "\n",
    "# END"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IV.1.2 Interpolatory quadrature rules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "An interpolatory quadrature rule consists of interpolating samples of a function and integrating\n",
    "the polynomial exactly. In the notes we constructed such rules by integrating the Lagrange basis,\n",
    "however, we can also compute the interpolatory polynomial by inverting the Vandermonde matrix.\n",
    "Here we explore this construction."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 2(a)** Complete the following function that computes an interpolatory quadrature\n",
    "$$\n",
    "\\int_0^1 f(x) {\\rm d}x â‰ˆ \\int_0^1 p(x) {\\rm d}x\n",
    "$$\n",
    "where $p(x)$ interpolates the data $ðŸ = [f_1,â€¦,f_n]$ (given as a vector) at the given points $ð± = [x_1,â€¦,x_n]$ (given as a vector).\n",
    "Hint: it is much easier to solve a linear system involving the Vandermonde matrix than to use a Lagrange basis."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function interpolatoryquadrature(f::AbstractVector, x::AbstractVector)\n",
    "    if length(f) â‰  length(x)\n",
    "        error(\"lengths must match\")\n",
    "    end\n",
    "    # TODO: Compute the coefficients of the interpolatory polynomial and integrate it exactly.\n",
    "    # SOLUTION\n",
    "        n = length(f)\n",
    "        V = x .^ (0:n-1)'\n",
    "        c = V \\ f\n",
    "        ret = 0\n",
    "        # There are simpler ways to write the following but for clearness lets just do a for-loop:\n",
    "        for k = 1:n\n",
    "            ret += c[k]/k # use the fact that âˆ«_0^1 x^k dx = 1/(k+1)\n",
    "        end\n",
    "        ret\n",
    "    # END\n",
    "end\n",
    "\n",
    "x = range(0, 1, 10)\n",
    "@test interpolatoryquadrature(exp.(x), x) â‰ˆ exp(1)-1"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 2(b)**  Plot the error for the number of evenly spaced points $n = 2, 3, â€¦, 100$ for approximating the integrals\n",
    "$$\n",
    "âˆ«_0^1 \\exp x {\\rm d}x  = â„¯ - 1, âˆ«_0^1 {{\\rm d} x \\over 25x^2 + 1} = {\\rm arctan}(5)/5.\n",
    "$$\n",
    "How does the convergence behaviour compare with the Trapezium rule? Does the approximation appear to be stable?\n",
    "Does using `BigFloat` improve the results? (Hint: `range(0,big(1),n)` will make a sequence of `BigFloat` points.)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "nanabs(x) = x == 0 ? NaN : abs(x)\n",
    "# TODO: plot the errors for 2,â€¦,100 evenly spaced points for approximating the integral of exp(x) and 1/(25x^2+1)\n",
    "# SOLUTION\n",
    "using Plots\n",
    "ns = 2:100\n",
    "errs = [(x = range(0,1,n); nanabs(interpolatoryquadrature(exp.(x), x) - (exp(1)-1))) for n=ns]\n",
    "plot(ns, errs;yscale=:log10) # error appears exponential (actually it's faster than exponential!)\n",
    "errs = [(x = range(0,1,n); nanabs(interpolatoryquadrature(1 ./ (25x.^2 .+ 1), x) - atan(5)/5)) for n=ns]\n",
    "plot!(ns, errs;yscale=:log10) # error appears to decay exponentially but then gets stuck ðŸ˜¢ But does better than interpolation\n",
    "errs = [(x = range(0,big(1),n); nanabs(interpolatoryquadrature(1 ./ (25x.^2 .+ 1), x) - atan(big(5))/5)) for n=ns]\n",
    "plot!(ns, errs;yscale=:log10) # using BigFloat does better\n",
    "# END"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 2(c)** Repeat the previous problem with the points $x_j = (\\cos Î¸_j + 1)/2$ where $Î¸_j$ are $n$ evenly spaced points\n",
    "between $0$ and $Ï€$. How do the results compare with evenly spaced points?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: plot the errors for 2,â€¦,100 points that are cosines of evenly spaced points, shifted/scaled to be between 0 and 1.\n",
    "# SOLUTION\n",
    "errs = [(x = (cos.(range(0,big(Ï€),n)) .+ 1)/2; nanabs(interpolatoryquadrature(1 ./ (25x.^2 .+ 1), x) - atan(5)/5)) for n=ns]\n",
    "ns = 2:100\n",
    "errs = [(x = (cos.(range(0,Ï€,n)) .+ 1)/2; nanabs(interpolatoryquadrature(exp.(x), x) - (exp(1)-1))) for n=ns]\n",
    "plot(ns, errs;yscale=:log10) # error still appears exponential at roughly the same rate as evenly spaced point\n",
    "errs = [(x =  (cos.(range(0,Ï€,n)) .+ 1)/2; nanabs(interpolatoryquadrature(1 ./ (25x.^2 .+ 1), x) - atan(5)/5)) for n=ns]\n",
    "plot!(ns, errs;yscale=:log10) # errorstill  appears to decay exponentially but then gets stuck ðŸ˜¢\n",
    "errs = [(x =  (cos.(range(0,big(Ï€),n)) .+ 1)/2; nanabs(interpolatoryquadrature(1 ./ (25x.^2 .+ 1), x) - atan(big(5))/5)) for n=ns]\n",
    "plot!(ns, errs;yscale=:log10) # using BigFloat does better. This choice of points converges much faster.\n",
    "\n",
    "# END"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 3** Typically it's more convenient to compute the quadrature weights $w_j$ so that\n",
    "$$\n",
    "\\int_0^1 f(x) {\\rm d}x â‰ˆ \\int_0^1 p(x) {\\rm d}x = âˆ‘_{j=1}^n w_j f(x_j).\n",
    "$$\n",
    "Compute these weights by solving a linear system involving the transpose of the Vandermonde  matrix."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function interpolatoryweights(x::AbstractVector)\n",
    "    # TODO: Construct the interpolatory quadrature weights as a vector by solving a linear system involving V'\n",
    "    # SOLUTION\n",
    "    # The Vandermonde matrix gives the map to coefficients. We just need to multiply by a row vector\n",
    "    # corresponding to integrating the monomials exactly. That is, multiplying a vector by\n",
    "    # [1 1/2 â€¦ 1/n] * inv(V)\n",
    "    # gives the weights as a row vector. But we want a column vector here so we transpose this.\n",
    "    # Here's a very brief version, but feel free to translate this to a comprehension or for-loop:\n",
    "    n = length(x)\n",
    "    V = x .^ (0:n-1)'\n",
    "    V' \\ (1 ./ (1:n))\n",
    "    # END\n",
    "end\n",
    "\n",
    "# We test on the example from the notes:\n",
    "@test interpolatoryweights([0,1/4,1]) â‰ˆ [-1/6, 8/9, 5/18]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IV.1.3 Polynomial regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To overcome issues with interpolation we will instead use regression: use more points than\n",
    "the degree of the polynomial. As an example, suppose we want to fit noisy data by a quadratic\n",
    "$$\n",
    "p(x) = câ‚€ + câ‚ x + câ‚‚ x^2.\n",
    "$$\n",
    "That is, we want to choose $câ‚€,câ‚,câ‚‚$ at data samples $x_1, â€¦, x_m$ so that the following is true:\n",
    "$$\n",
    "câ‚€ + câ‚ x_j + câ‚‚ x_j^2 â‰ˆ f_j\n",
    "$$\n",
    "where $f_j$ are given by data. We can reinterpret this as a least squares problem: minimise the norm\n",
    "$$\n",
    "\\left\\| \\begin{bmatrix} 1 & x_1 & x_1^2 \\\\ â‹® & â‹® & â‹® \\\\ 1 & x_m & x_m^2 \\end{bmatrix}\n",
    "\\begin{bmatrix} pâ‚€ \\\\ pâ‚ \\\\ pâ‚‚ \\end{bmatrix} - \\begin{bmatrix} f_1 \\\\ â‹® \\\\ f_m \\end{bmatrix} \\right \\|\n",
    "$$\n",
    "When a matrix is rectangular `\\` solves a least squares problem for us:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "m,n = 100,3\n",
    "\n",
    "ð± = range(0,1; length=m) # 100 points\n",
    "ðŸ = 2 .+ ð± .+ 2ð±.^2 .+ 0.1 .* randn.() # Noisy quadratic samples, built with broadcast notation.\n",
    "\n",
    "V = ð± .^ (0:2)'  # 100 x 3 Vandermonde matrix, equivalent to [ones(m) x x.^2]\n",
    "\n",
    "ðœ = V \\ ðŸ # coefficients are, very roughly, [2,1,2]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can visualise the fit:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ð  =range(0, 1; length=1000)\n",
    "\n",
    "p = x -> ðœ[1] + ðœ[2]x + ðœ[3]x^2\n",
    "\n",
    "scatter(ð±, ðŸ; label=\"samples\", legend=:bottomright)\n",
    "plot!(ð , p.(ð ); label=\"quadratic\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "-----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 4** Repeat  Problem 1 but now using _least squares_: instead of interpolating,\n",
    "use least squares on a large grid: choose the coefficients of a degree $(n-1)$ polynomial so that\n",
    "$$\n",
    "    \\left\\| \\begin{bmatrix} p(x_1) \\\\ â‹® \\\\ p(x_m) \\end{bmatrix} - \\begin{bmatrix} f(x_1) \\\\ â‹® \\\\ f(x_m) \\end{bmatrix} \\right \\|.\n",
    "$$\n",
    "is minimised, where $n = 50$ and $m = 500$.\n",
    "Does this improve the accuracy near the endpoints? Do you think convergence for a least squares approximation\n",
    "is dictated by the radius of convergence of the corresponding Taylor series?\n",
    "Hint: use the rectangular Vandermonde matrix to setup the Least squares system. The solution will look extremely similar to Problem 1."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: approximate 1/(10x^2 + 1) and 1/(25x^2 + 1) using a least squares system.\n",
    "\n",
    "# SOLUTION\n",
    "n = 50 # use basis [1,x,â€¦,x^(49)]\n",
    "ð± = range(-1, 1; length=500) # least squares grid\n",
    "ð  = range(-1, 1; length=2000) # plotting grid\n",
    "\n",
    "V = ð± .^ (0:n-1)'\n",
    "V_g = ð  .^ (0:n-1)'\n",
    "f_4 = x -> 1/(4x^2 + 1)\n",
    "ðœ_4 = V \\ f_4.(ð±)\n",
    "f_25 = x -> 1/(25x^2 + 1)\n",
    "ðœ_25 = V \\ f_25.(ð±)\n",
    "\n",
    "plot(ð , V_g*ðœ_4; ylims=(-1,1))\n",
    "plot!(ð , V_g*ðœ_25)\n",
    "\n",
    "# Yes, now both approximations appear to be converging.\n",
    "# This is despite the radius of convergence of both functions being\n",
    "# smaller than the interval of interpolation.\n",
    "\n",
    "# END"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IV.2 Differential Equations via Finite Differences"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now turn to an important application of banded linear algebra:\n",
    "approximating solutions to linear differential equations. We will focus on first and second order\n",
    "but the techniques generalise beyond this, to vector problems, nonlinear differential equations, and partial differential equations.\n",
    "In particular we explore _finite difference_ approximations which use divided differences to replace derivatives.\n",
    "These are the most basic type of numerical method and many powerful alternatives\n",
    "exist, including Finite Element Methods and spectral methods."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IV.2.1 Indefinite integration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can use the right-sided divided difference to approximate derivatives.  Let's do an example of integrating $\\cos x$ by discretising the ODE\n",
    "$$\n",
    " u(0) = c, \\qquad u'(x) = f(x)\n",
    "$$\n",
    "and see if our method matches\n",
    "the true answer of $\\sin x$. Recall from the notes that this equation can be approximated by $u_k$ solving the bidiagonal linear system\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    -1/h & 1/h \\\\\n",
    "    & â‹± & â‹± \\\\\n",
    "    && -1/h & 1/h \\end{bmatrix} \\begin{bmatrix}u_0\\\\u_1\\\\â‹®\\\\u_n\\end{bmatrix} = \\begin{bmatrix}c\\\\ f(x_0)\\\\ â‹® \\\\ f(x_{n-1})\\end{bmatrix}.\n",
    "$$\n",
    "We can construct the bidiagonal matrix as follows:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "n = 10\n",
    "x = range(0, 1; length=n+1) # makes an n+1 point evenly spaced grid\n",
    "h = step(x) # equivalent to 1/n\n",
    "L = Bidiagonal([1; fill(1/h, n)], fill(-1/h, n), :L)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can use this bidiagonal matrix along with `\\` to solve the\n",
    "system via forward substitution:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "c = 0 # u(0) = 0\n",
    "f = x -> cos(x)\n",
    "\n",
    "ðŸ = f.(x[1:end-1]) # evaluate f at all but the last point\n",
    "ð› = [c; ðŸ]\n",
    "ð® = L \\ ð› # integrate using forward-differences\n",
    "\n",
    "plot(x, sin.(x); label=\"sin(x)\", legend=:bottomright)\n",
    "scatter!(x, ð®; label=\"forward\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    " We can estimate how fast it converges by measuring\n",
    "the âˆž-norm error (using $\\| ð± \\|_âˆž := \\max |x_k|$ which\n",
    "is implemented as `norm(x,Inf)`):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Error from indefinite integration with c and f\n",
    "function forward_err(u, c, f, n)\n",
    "    x = range(0, 1; length = n+1)\n",
    "    h = step(x) # equivalent to 1/n\n",
    "    L = Bidiagonal([1; fill(1/h, n)], fill(-1/h, n), :L)\n",
    "    ð® = L\\ [c; f.(x[1:end-1])]\n",
    "    errs = ð® - u.(x) # compare numerics with \"true\" result\n",
    "    norm(errs, Inf) # measure âˆž-norm error\n",
    "end\n",
    "\n",
    "\n",
    "ns = 10 .^ (1:8) # solve up to n = 10 million\n",
    "scatter(ns, forward_err.(sin, 0, f, ns); xscale=:log10, yscale=:log10, label=\"forward\")\n",
    "plot!(ns, ns .^ (-1); label=\"1/n\", linestyle=:dash)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see that the method converges linearly (like $O(n^{-1})$)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 5(a)** In the problem sheet we derived Backward Euler using the left-sided divided difference\n",
    "$$\n",
    "  u'(x) â‰ˆ {u(x) - u(x-h) \\over h}\n",
    "$$\n",
    "Implement Backward Euler to approximate\n",
    "indefinite-integration. How does the error compare to forward\n",
    "for $f(x) = \\cos x$ on the interval $[0,1]$?\n",
    "Use the method to approximate the indefinite intergral of\n",
    "$$\n",
    "\\exp(\\exp x \\cos x + \\sin x)\n",
    "$$\n",
    "to 3 digits."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: Implement Backward Euler by constructing a lower bidiagonal linear system.\n",
    "# SOLUTION\n",
    "\n",
    "# To help with understanding we will also plot the errors even though this\n",
    "# wasn't asked for in the question. We first compare backward and forward Euler:\n",
    "c = 0 # u(0) = 0\n",
    "f = x -> cos(x)\n",
    "n = 10\n",
    "\n",
    "x = range(0,1;length=n+1)\n",
    "h=step(x)\n",
    "A = Bidiagonal([1; fill(1/h, n)], fill(-1/h, n), :L)\n",
    "ub = A\\[c; f.(x[2:end])]\n",
    "uf = A \\ [c; f.(x[1:end-1])]\n",
    "\n",
    "plot(x, sin.(x); label=\"sin(x)\", legend=:bottomright)\n",
    "scatter!(x, ub; label=\"backward\")\n",
    "scatter!(x, uf; label=\"forward\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Comparing each method's errors, we see that the backward method has the same error as the forward method:\n",
    "\n",
    "\n",
    "function forward_err(u, c, f, n)\n",
    "    x = range(0, 1; length = n+1)\n",
    "    h = step(x) # equivalent to 1/n\n",
    "    L = Bidiagonal([1; fill(1/h, n)], fill(-1/h, n), :L)\n",
    "    ð® = L\\ [c; f.(x[1:end-1])]\n",
    "    errs = ð® - u.(x) # compare numerics with \"true\" result\n",
    "    norm(errs, Inf) # measure âˆž-norm error\n",
    "end\n",
    "\n",
    "function back_err(u, c, f, n)\n",
    "    x = range(0,1;length=n+1)\n",
    "    h=step(x)\n",
    "    A = Bidiagonal([1; fill(1/h, n)], fill(-1/h, n), :L)\n",
    "    ub = A\\[c; f.(x[2:end])]\n",
    "    norm(ub - u.(x), Inf)\n",
    "end\n",
    "\n",
    "c = 0 # u(0) = 0\n",
    "f = x -> cos(x)\n",
    "m = (x[1:end-1] + x[2:end])/2 # midpoints\n",
    "ns = 10 .^ (1:8) # solve up to n = 10 million\n",
    "\n",
    "\n",
    "scatter(ns, forward_err.(sin, 0, f, ns); xscale=:log10, yscale=:log10, label=\"forward\")\n",
    "scatter!(ns, back_err.(sin, 0, f, ns); label=\"back\",alpha=0.5)\n",
    "plot!(ns, ns .^ (-1); label=\"1/n\")\n",
    "plot!(ns, ns .^ (-2); label=\"1/n^2\")\n",
    "\n",
    "\n",
    "# Finally we get to the last part. One can increase n until\n",
    "# 3 digits don't change. Or we can use the fact that the rate of convergence\n",
    "# is O(n^(-1)) and guess that n = 100k suffices.\n",
    "\n",
    "\n",
    "c = 0 # u(0) = 0\n",
    "n = 100_000\n",
    "\n",
    "##functions defined in the solutions to problem sheet 2\n",
    "f = x -> exp(exp(x)cos(x) + sin(x))\n",
    "\n",
    "x = range(0,1;length=n+1)\n",
    "h=step(x)\n",
    "A = Bidiagonal([1; fill(1/h, n)], fill(-1/h, n), :L)\n",
    "uf = A\\[c; f.(x[2:end])]\n",
    "# Gives the values uf u on the grid to at least 3 digits\n",
    "\n",
    "# END"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 5(b)** Implement indefinite-integration\n",
    "where we impose the equation on the midpoints $xÌƒ_1,â€¦,xÌƒ_n$ defined as\n",
    "$$\n",
    "xÌƒ_j = {x_{j+1} + x_j \\over 2} = a + (j-1/2)h\n",
    "$$\n",
    "using the central difference formula\n",
    "$$\n",
    "u'(xÌƒ_j) â‰ˆ {u(x_j) - u(x_{j-1}) \\over h}\n",
    "$$\n",
    "By plotting the errors show that this method converges at\n",
    "a faster rate than Forward or Backward Euler for $f(x) = \\cos x$ on the interval $[0,1]$."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: Discretise at midpoints rather than our grid. The solution is still approximated on the original grid.\n",
    "# SOLUTION\n",
    "\n",
    "\n",
    "# The system is identical to before, just we evaluate the\n",
    "# right-hand side at the midpoints.\n",
    "\n",
    "n = 10\n",
    "x = range(0, 1; length=n+1)\n",
    "h = step(x)\n",
    "A = Bidiagonal([1; fill(1/h, n)], fill(-1/h, n), :L)\n",
    "c = 0 # u(0) = 0\n",
    "f = x -> cos(x)\n",
    "\n",
    "xÌƒ = (x[2:end] + x[1:end-1])/2 # could also be made with a comprehension\n",
    "ðŸ = f.(xÌƒ) # evaluate f at all but last points\n",
    "ð® = A \\ [c; ðŸ]\n",
    "\n",
    "plot(x, sin.(x); label=\"sin(x)\", legend=:bottomright)\n",
    "scatter!(x, ð®; label=\"average grid point\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Comparing the error to the midpoint method, we see that the errors are very similar:\n",
    "\n",
    "function mid_err(u, c, f, n)\n",
    "    x = range(0, 1; length = n+1)\n",
    "    h = step(x) # equivalent to 1/n\n",
    "    L = Bidiagonal([1; fill(1/h, n)], fill(-1/h, n), :L)\n",
    "    xÌƒ = (x[2:end] + x[1:end-1])/2\n",
    "    ðŸ = f.(xÌƒ) # evaluate f at all but last points\n",
    "\n",
    "    ð® = L\\ [c; ðŸ]\n",
    "    errs = ð® - u.(x) # compare numerics with \"true\" result\n",
    "    norm(errs, Inf) # measure âˆž-norm error\n",
    "end\n",
    "\n",
    "c = 0 # u(0) = 0\n",
    "f = x -> cos(x)\n",
    "ns = 10 .^ (1:8) # solve up to n = 10 million\n",
    "\n",
    "\n",
    "scatter(ns, mid_err.(sin, 0, f, ns); xscale=:log10, yscale=:log10, label=\"mid\")\n",
    "scatter!(ns, forward_err.(sin, 0, f, ns); label=\"forward\")\n",
    "plot!(ns, ns .^ (-1); label=\"1/n\")\n",
    "plot!(ns, ns .^ (-2); label=\"1/n^2\")\n",
    "# The error now decreases quadratically. Interestingly: we do not see\n",
    "# the same growth in error as we did for computing derivatives. That is:\n",
    "# solving an ODE is a more stable process than applying a differential operator.\n",
    "# END"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IV.2.2 Forward Euler"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now adapt the approach for more general ODEs of the form\n",
    "$$\n",
    "  u'(x) + Ï‰(x)u(x) = f(x), u(0) = c.\n",
    "$$\n",
    "We now have the system:\n",
    "$$\n",
    "\\underbrace{\\begin{bmatrix}\n",
    "1 \\\\\n",
    "Ï‰(x_0)-1/h & 1/h \\\\\n",
    "& â‹± & â‹± \\\\\n",
    "&& Ï‰(x_{n-1})-1/h & 1/h \\end{bmatrix}}_L \\underbrace{\\begin{bmatrix}u_0 \\\\ u_1 \\\\ â‹® \\\\ u_n\\end{bmatrix} }_{ð®} = \\begin{bmatrix} c \\\\ f(x_0) \\\\ â‹® \\\\ f(x_{n-1}) \\end{bmatrix}\n",
    "$$\n",
    "Consider the simple example:\n",
    " $$\n",
    " u(0) = 1, u' + x u = {\\rm e}^x\n",
    " $$\n",
    " which has an exact solution in terms of a special error function\n",
    " (which I determined using Mathematica)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using SpecialFunctions\n",
    "c = 1\n",
    "Ï‰ = x -> x\n",
    "n = 200\n",
    "x = range(0, 1; length=n+1)\n",
    "# exact solution, found in Mathematica\n",
    "u = x -> -(1/2)*exp(-(1+x^2)/2)*(-2sqrt(â„¯) + sqrt(2Ï€)erfi(1/sqrt(2)) - sqrt(2Ï€)erfi((1 + x)/sqrt(2)))\n",
    "\n",
    "h = step(x)\n",
    "L = Bidiagonal([1; fill(1/h, n)], Ï‰.(x[1:end-1]) .- 1/h, :L)\n",
    "\n",
    "ð› = [c; exp.(x[1:end-1])]\n",
    "ð® = L \\ ð›\n",
    "\n",
    "plot(x, u.(x); label=\"u(x)\", legend=:bottomright)\n",
    "scatter!(x, ð®; label=\"forward\")\n",
    "\n",
    "# We see that it is converging to the true result."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem  6** Implement backward Euler for solving:\n",
    "$$\n",
    "\\begin{align*}\n",
    "u(0) &= 1, u'(t) - \\cos(t) u(t) = t\n",
    "\\end{align*}\n",
    "$$\n",
    "on the interval $[0,1]$. Approximate $u(1)$ to three digits accuracy."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: Implement backward Euler for the case with a variable coefficient.\n",
    "\n",
    "# SOLUTION\n",
    "\n",
    "function first_eq(n)\n",
    "    x = range(0, 1; length=n+1)\n",
    "    #find the step-size h\n",
    "    h = step(x)\n",
    "    L = Bidiagonal([1; fill(1/h, n) - cos.(x[2:end])], fill(-1/h, n), :L)\n",
    "    L \\ [1; x[2:end]]\n",
    "end\n",
    "\n",
    "for n in 2 .^ (1:13)\n",
    "    println(first_eq(n)[end]) # print out final value\n",
    "end\n",
    "# We can guess that that $u(1) â‰ˆ 2.96$ to three digits since those digits have stopped changing.\n",
    "\n",
    "# END"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "-----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IV.2.3 Poisson equation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now consider the Poisson equation with Dirichlet\n",
    "boundary conditions. In particular consider a case where\n",
    "we know the true answer: if $u(x) = \\cos x^2$ then it solves the ODE:\n",
    "$$\n",
    "\\begin{align*}\n",
    "u(0) = \\underbrace{1}_c \\\\\n",
    "u''(x) = \\underbrace{-4x^2 \\cos(x^2) - 2\\sin(x^2)}_{f(x)} \\\\\n",
    "u(1) = \\underbrace{\\cos 1}_d\n",
    "\\end{align*}\n",
    "$$\n",
    "We approximate it by the solution to the tridiagonal system:\n",
    "$$\n",
    "\\underbrace{\\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    1/h^2 & -2/h^2 & 1/h \\\\\n",
    "    & â‹± & â‹± & â‹± \\\\\n",
    "   && 1/h^2 & -2/h^2 & 1/h \\\\\n",
    "   &&&& 1 \\end{bmatrix}}_A \\underbrace{\\begin{bmatrix}u_0\\\\u_1\\\\â‹®\\\\u_n\\end{bmatrix} }_{ð®} = \\underbrace{\\begin{bmatrix}c\\\\ f(x_1)\\\\ f(x_2)\\\\ â‹® \\\\ f(x_{n-1})\\\\ d\\end{bmatrix} }_{ð›}\n",
    "$$\n",
    "We first construct the matrix $A$ using `Tridiagonal`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "n = 20\n",
    "x = range(0, 1; length = n + 1)\n",
    "h = step(x)\n",
    "A = Tridiagonal([fill(1/h^2, n-1); 0],\n",
    "                [1; fill(-2/h^2, n-1); 1],\n",
    "                [0; fill(1/h^2, n-1)])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Thus we get an approximation to our (known) solution:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "u = x -> cos(x^2)\n",
    "f = x -> -4x^2*cos(x^2) - 2sin(x^2)\n",
    "ð› =  [1; f.(x[2:end-1]); cos(1)]\n",
    "ð® = A \\ ð›\n",
    "plot(x, u.(x); label=\"u(x)\", legend=:bottomright)\n",
    "scatter!(x, ð®; label=\"finite differences\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "-----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 7(a)** Estimate the rate of convergence in the âˆž-norm using the previous example with an increasing number of grid points."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: Plot the âˆž-norm error and estimate the convergence rate.\n",
    "# SOLUTION\n",
    "\n",
    "function poisson_err(u, c_0, c_1, f, n)\n",
    "    x = range(0, 1; length = n+1)\n",
    "    h = step(x)\n",
    "    T = Tridiagonal([fill(1/h^2, n-1); 0], [1; fill(-2/h^2, n-1); 1], [0; fill(1/h^2, n-1)])\n",
    "    uá¶  = T \\ [c_0; f.(x[2:end-1]); c_1]\n",
    "    norm(uá¶  - u.(x), Inf)\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "ns = 10 .^ (1:8) # solve up to n = 10 million\n",
    "scatter(ns, poisson_err.(u, 1, cos(1), f, ns); xscale=:log10, yscale=:log10, label=\"error\")\n",
    "plot!(ns, ns .^ (-2); label=\"1/n^2\")\n",
    "# END"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 7(b)** Construct a finite-difference approximation to the\n",
    "forced Helmholtz equation\n",
    "$$\n",
    "\\begin{align*}\n",
    "u(0) &= 0 \\\\\n",
    "u(1) &= 0 \\\\\n",
    "u'' + k^2 u &= {\\rm e}^x\n",
    "\\end{align*}\n",
    "$$\n",
    "and find an $n$ such  the error is less than $10^{-4}$ when compared\n",
    "with the true solution for $k=10$:\n",
    "$$\n",
    "u(x) = (-\\cos(k x) + {\\rm e}^x \\cos(k x)^2 + \\cot(k) \\sin(k x) - {\\rm e} \\cos(k) \\cot(k) \\sin(k x) - {\\rm e} \\sin(k) \\sin(k x) + {\\rm e}^x \\sin(k x)^2)/(1 + k^2)\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: Generalise the second-order finite differences to allow for a $k^2 u$ term.\n",
    "\n",
    "# SOLUTION\n",
    "##Â We do something slightly different and use SymTridiagonal.\n",
    "# You can also do this with Tridiagonal\n",
    "function helm(k, n)\n",
    "    x = range(0, 1; length = n+1)\n",
    "    h = step(x)\n",
    "    T = SymTridiagonal(ones(n-1)*(-2/h^2 + k^2),ones(n-2)*1/h^2)\n",
    "    u = T \\ exp.(x[2:end-1])\n",
    "    [0; u; 0]\n",
    "end\n",
    "\n",
    "k = 10\n",
    "u = x -> (-cos(k*x) + exp(x)cos(k*x)^2 + cot(k)sin(k*x) - â„¯*cos(k)cot(k)sin(k*x) - â„¯*sin(k)sin(k*x) + exp(x)sin(k*x)^2)/(1 + k^2)\n",
    "\n",
    "n = 2048\n",
    "x = range(0, 1; length=n+1)\n",
    "@test norm(helm(k, n) - u.(x)) â‰¤ 1E-4\n",
    "# END"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 8(a)** Consider the Helmholtz equations\n",
    "$$\n",
    "\\begin{align*}\n",
    "u(0) &= 0 \\\\\n",
    "u(1) &= 0 \\\\\n",
    "u'' + k^2 u &= {\\rm e}^x\n",
    "\\end{align*}\n",
    "$$\n",
    "discretised with finite-differences to result in a tridiagonal system.\n",
    "Use the `lu` function without pivoting to\n",
    "compute the LU factorization of the tridiagonal matrix. What sparsity structure\n",
    "do you observe in `L` and `U`? Does this structure depend on $n$ or $k$?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: Apply lu to the discretisation for Helmholtz derived in the last lab and investigate its structure.\n",
    "\n",
    "# SOLUTION\n",
    "\n",
    "\n",
    "# We make a function that returns the Helmholtz matrix:\n",
    "function helmholtz(n, k)\n",
    "    x = range(0, 1; length = n + 1)\n",
    "    h = step(x)\n",
    "    Tridiagonal([fill(1/h^2, n-1); 0],\n",
    "                    [1; fill(k^2-2/h^2, n-1); 1],\n",
    "                    [0; fill(1/h^2, n-1)])\n",
    "end\n",
    "\n",
    "lu(helmholtz(20, 2), NoPivot()) # L is lower bidiagonal and U is upper bidiagonal, regardless of n or k\n",
    "# END"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 8(b)** Repeat Problem 8(a) but with a PLU factorisation.\n",
    "Are $L$ and $U$ still banded?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: Check sparsity of PLU factorisation\n",
    "\n",
    "# SOLUTION\n",
    "lu(helmholtz(20, 2)).L # L is no longer banded: its penultimate row is dense\n",
    "# END"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.2",
   "language": "julia"
  }
 },
 "nbformat": 4
}
